{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# classification models\n",
    "#from sklearn.preprocessing import StandardScalar\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import class_weight\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# neural network\n",
    "#import keras.backend as Kb\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "\n",
    "#scaling methods\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "# resampling methods modules\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "#feature selecti\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_raw = pd.read_csv('/Users/charlotteout/Documents/AML/task2/X_train.csv').values\n",
    "train_y_raw = pd.read_csv('/Users/charlotteout/Documents/AML/task2/y_train.csv').values\n",
    "test_x_raw = pd.read_csv(\"/Users/charlotteout/Documents/AML/task2/X_test.csv\").values\n",
    "\n",
    "N_FEATURES = train_x_raw[0].size-1\n",
    "\n",
    "X_train_data = train_x_raw[:,1:N_FEATURES+1]\n",
    "y_train_data = train_y_raw[:,1]\n",
    "\n",
    "X_test_data = test_x_raw[:,1:N_FEATURES+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardscaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit(data)\n",
    "    return scaler\n",
    "\n",
    "def PowTrans(data):\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "    data = scaler.fit(data)\n",
    "    return scaler\n",
    "\n",
    "def Robustnorm(data):\n",
    "    scaler = RobustScaler()\n",
    "    fitscal = scaler.fit(data)\n",
    "    return fitscal\n",
    "\n",
    "def Quanttrans(data):\n",
    "    scaler = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "    fitscal = scaler.fit(data)\n",
    "    return fitscal\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# svm classifier model\n",
    "def svc(data_set_X, data_set_y):\n",
    "    model = SVC(class_weight='balanced',gamma=0.00001, kernel='rbf',C=100,random_state=0)\n",
    "    model.fit(data_set_X, data_set_y)\n",
    "    return model\n",
    "\n",
    "# mlp classifier model\n",
    "def mlp(data_set_X, data_set_y):\n",
    "    model = MLPClassifier(random_state=0)\n",
    "    model.fit(data_set_X, data_set_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# ada resampling\n",
    "def r_ada(data_set_X, data_set_Y):\n",
    "    ada = ADASYN(random_state=SEED)\n",
    "    X_res, y_res = ada.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "# bsm resampling\n",
    "def r_bsmote(data_set_X, data_set_Y):\n",
    "    bsm = BorderlineSMOTE(random_state=0)\n",
    "    X_res, y_res = bsm.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "# smote resampling\n",
    "def r_smote(data_set_X, data_set_Y):\n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_res, y_res = sm.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "def SVM_smote(data_set_X, data_set_Y):\n",
    "    svm_smote = SVMSMOTE(random_state=0)\n",
    "    X_res, y_res = svm_smote.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "def smote_enn(data_set_X, data_set_Y):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_res, y_res = smote_enn.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "def smote_tomek(data_set_X, data_set_Y):\n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    X_res, y_res = smote_tomek.fit_resample(data_set_X, data_set_Y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= Standardscaler(X_train_data)\n",
    "X_train_data = scaler.transform(X_train_data)\n",
    "X_test_data =scaler.transform(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
       "                         'gamma': array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_range = np.logspace(-2,10,13)\n",
    "gamma_range = np.logspace(-9,3,13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=cv)\n",
    "grid.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100.0, 'gamma': 1e-05} 0.815\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_,grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kfold(classifier, X, y, k, score1, score2):\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    mses_eval = []\n",
    "    mses_unbalaced = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test, y_train = X[train_index], X[test_index], y[train_index]\n",
    "        scaler = Standardscaler(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # X_train, y_train = resample(X_train, y_train)\n",
    "        model = classifier(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        mses_eval.append(score1(y[test_index], y_pred_test))\n",
    "        mses_unbalaced.append(score2(y[test_index], y_pred_test, average='weighted'))\n",
    "        print(mses_eval)\n",
    "        print(mses_unbalaced)\n",
    "\n",
    "    return np.mean(mses_eval), np.std(mses_eval), np.mean(mses_unbalaced), np.std(mses_unbalaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7050717852684145]\n",
      "[0.7291666666666666]\n",
      "[0.7050717852684145, 0.7112112723080374]\n",
      "[0.7291666666666666, 0.7395833333333334]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793, 0.6926736043501149]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667, 0.7270833333333333]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793, 0.6926736043501149, 0.6716126063952151]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667, 0.7270833333333333, 0.75625]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793, 0.6926736043501149, 0.6716126063952151, 0.6800392558457075]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667, 0.7270833333333333, 0.75625, 0.7333333333333333]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793, 0.6926736043501149, 0.6716126063952151, 0.6800392558457075, 0.6657925681609491]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667, 0.7270833333333333, 0.75625, 0.7333333333333333, 0.7104166666666667]\n",
      "[0.7050717852684145, 0.7112112723080374, 0.726713400041457, 0.6943155651785408, 0.6644697243288793, 0.6926736043501149, 0.6716126063952151, 0.6800392558457075, 0.6657925681609491, 0.703652309725476]\n",
      "[0.7291666666666666, 0.7395833333333334, 0.7458333333333333, 0.7541666666666667, 0.7104166666666667, 0.7270833333333333, 0.75625, 0.7333333333333333, 0.7104166666666667, 0.7395833333333334]\n",
      "K-fold cross-validation for balanced accuracy score: mean  0.69156, std  0.01972\n",
      "K-fold cross-validation for recall score: mean  0.73458, std  0.01512\n"
     ]
    }
   ],
   "source": [
    "mean1, std1, mean2, std2 = do_kfold(svc,X_train_data, y_train_data, 10, balanced_accuracy_score, recall_score)\n",
    "\n",
    "\n",
    "#kfold so makes sense that its lower\n",
    "print('K-fold cross-validation for balanced accuracy score: mean % 5.5f, std % 5.5f' %(mean1, std1))\n",
    "print('K-fold cross-validation for recall score: mean % 5.5f, std % 5.5f' %(mean2, std2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Write predictions into csv file\n",
    "'''\n",
    "\n",
    "# function to write csv file\n",
    "def csv_write(prediction):\n",
    "\n",
    "    # size of prediction\n",
    "    n_size = prediction.size\n",
    "\n",
    "    # header\n",
    "    header = []\n",
    "    header.append('id')\n",
    "    header.append('y')\n",
    "\n",
    "    # array containing ids\n",
    "    ids = []\n",
    "\n",
    "    for i in range(0, n_size):\n",
    "        ids.append(float(i))\n",
    "\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    # write file\n",
    "    with open('predictionEIGHT.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = ['id', 'y'])\n",
    "        writer.writeheader()\n",
    "        nsize = prediction.size\n",
    "        for i in range(0, nsize):\n",
    "            row = {}\n",
    "            row['id'] = ids[i]\n",
    "            row['y'] = prediction[i]\n",
    "            writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= Standardscaler(X_train_data)\n",
    "X_train_data = scaler.transform(X_train_data)\n",
    "X_test_data =scaler.transform(X_test_data)\n",
    "\n",
    "model = svc(X_train_data, y_train_data)\n",
    "y_pred_test = model.predict(X_test_data)\n",
    "\n",
    "csv_write(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
